import json
import os
import glob
import time
import google.generativeai as genai
from dotenv import load_dotenv

# === è¨­å®šå€ ===
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=api_key)
model = genai.GenerativeModel('models/gemma-3-27b-it') 

def generate_chart_data(article_data):
    """
    å°ˆé–€è² è²¬ç”¢ç”Ÿã€Œåœ–è¡¨æ•¸æ“šã€èˆ‡ã€Œåœ–è¡¨é¡Œã€çš„ AI å‡½æ•¸
    """
    title = article_data['meta']['title']
    content = article_data['content']
    
    print(f"ğŸ“Š AI æ­£åœ¨ç‚ºæ–‡ç« è¨­è¨ˆåœ–è¡¨ï¼š{title[:20]}...")

    prompt = f"""
    ä½ æ˜¯ä¸€ä½é«˜ä¸­è‡ªç„¶ç§‘è€å¸«ã€‚é€™æ˜¯ä¸€ç¯‡ç§‘æ™®æ–‡ç« çš„å…§å®¹ï¼š
    
    ---
    {content[:1500]} 
    ---

    è«‹æ ¹æ“šæ–‡ç« å…§å®¹ï¼Œè¨­è¨ˆä¸€å€‹**ã€Œæ•¸æ“šåˆ†æé¡Œã€**ã€‚
    è«‹åˆ¤æ–·é©åˆçš„åœ–è¡¨é¡å‹ï¼ˆæŠ˜ç·šåœ–ã€é•·æ¢åœ–æˆ–æ•£ä½ˆåœ–ï¼‰ï¼Œä¸¦è™›æ§‹ä¸€çµ„ç¬¦åˆç§‘å­¸åŸç†çš„æ•¸æ“šã€‚

    è«‹åš´æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼è¼¸å‡ºï¼š

    {{
        "chart_config": {{
            "type": "line", // è«‹å¡«å…¥ "line" (æŠ˜ç·š), "bar" (é•·æ¢), æˆ– "scatter" (æ•£ä½ˆ)
            "title": "åœ–è¡¨æ¨™é¡Œ",
            "x_label": "Xè»¸åç¨±",
            "y_label": "Yè»¸åç¨±",
            "data_x": [æ•¸æ“š...], 
            "data_y": [æ•¸æ“š...]
        }},
        "question": "é¡Œç›®æ•˜è¿°...",
        "options": ["(A)...", "(B)...", "(C)...", "(D)..."],
        "correct_answer": "A",
        "explanation": "è©³è§£"
    }}
    
    æ³¨æ„ï¼š
    1. è‹¥æ˜¯æ¯”è¼ƒå¤šå€‹ä¸åŒé¡åˆ¥ï¼ˆå¦‚å¯¦é©—çµ„vså°ç…§çµ„ï¼‰ï¼Œè«‹ç”¨ "bar"ã€‚
    2. è‹¥æ˜¯è§€å¯Ÿéš¨æ™‚é–“/æº«åº¦è®ŠåŒ–çš„è¶¨å‹¢ï¼Œè«‹ç”¨ "line"æˆ–"scatter"ã€‚
    3. ã€é•·æ¢åœ– (bar)ã€‘ï¼šX è»¸ (data_x) å¿…é ˆæ˜¯ã€Œé¡åˆ¥åç¨±ã€(å­—ä¸²)ã€‚
       ä¾‹å¦‚ï¼šdata_x: ["å°ç…§çµ„", "å¯¦é©—çµ„A", "å¯¦é©—çµ„B"], data_y: [10, 50, 85]
    4. ã€æŠ˜ç·šåœ– (line) / æ•£ä½ˆåœ– (scatter)ã€‘ï¼šX è»¸é€šå¸¸æ˜¯ã€Œé€£çºŒæ•¸å€¼ã€(æ•¸å­—)ã€‚
       ä¾‹å¦‚ï¼šdata_x: [10, 20, 30, 40], data_y: [0.5, 0.8, 1.2, 1.5]
    5. æ•¸æ“šé»æ•¸é‡å»ºè­° 4~8 å€‹ã€‚
    """

    try:
        response = model.generate_content(prompt, generation_config={"temperature": 0.2})
        text = response.text.strip()
        
        # æ¸…æ´— Markdown æ¨™è¨˜ (é˜²å‘†)
        if text.startswith("```"):
            text = text.replace("```json", "").replace("```", "").strip()
            
        return json.loads(text)
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
        return None

def process_injection():
    # æƒææ‰€æœ‰æ–‡ç« 
    files = glob.glob("articles/**/*.json", recursive=True)
    
    count = 0
    for filepath in files:
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # æª¢æŸ¥ï¼šå¦‚æœé€™ç¯‡æ–‡ç« å·²ç¶“æœ‰ 'chart_quiz' æ¬„ä½ï¼Œå°±è·³éï¼Œé¿å…é‡è¤‡æµªè²»éŒ¢
            if "chart_quiz" in data:
                continue
                
            # å‘¼å« AI ç”Ÿæˆåœ–è¡¨è³‡æ–™
            chart_quiz_data = generate_chart_data(data)
            
            if chart_quiz_data:
                # æ³¨å…¥æ–°è³‡æ–™ï¼æˆ‘å€‘æŠŠé€™æ•´åŒ…å­˜é€² 'chart_quiz' æ¬„ä½
                data["chart_quiz"] = chart_quiz_data
                
                # å¯«å›æª”æ¡ˆ
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(data, f, indent=4, ensure_ascii=False)
                
                print(f"âœ… æˆåŠŸæ³¨å…¥åœ–è¡¨é¡Œï¼š{filepath}")
                count += 1
                
                # ä¼‘æ¯ä¸€ä¸‹é¿å… API é™åˆ¶
                time.sleep(2)
                
        except Exception as e:
            print(f"âš ï¸ è™•ç†æª”æ¡ˆå‡ºéŒ¯ {filepath}: {e}")
            continue

    if count == 0:
        print("ğŸ“­ æ²’æœ‰éœ€è¦è™•ç†çš„æ–‡ç«  (æ‰€æœ‰æ–‡ç« éƒ½å·²æœ‰åœ–è¡¨ï¼Œæˆ–è³‡æ–™å¤¾ç‚ºç©º)ã€‚")
    else:
        print(f"ğŸ‰ å®Œæˆï¼å…±ç‚º {count} ç¯‡æ–‡ç« åŠ ä¸Šäº†åœ–è¡¨é¡Œã€‚")

if __name__ == "__main__":
    process_injection()